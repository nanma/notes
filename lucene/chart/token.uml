@startuml
Class Token:LUCENE_BASE {

}

Abstract TokenStream {
      + {abstract} Token* next()
}

Abstract Tokenizer {
         + Reader* input
}

TokenStream <|-- Tokenizer  

Abstract CharTokenize {
      - int32_t offset, bufferIndex, dataLen
      - TCHAR buffer[]
      - const TCHAR* ioBuffer
      # {abstract} bool isTokenChar()
      # {abstract} TCHAR normalize()
      + Token* next()
}

Tokenizer <|-- CharTokenize

Class LetterTokenizer {
      # bool isTokenChar()
}
CharTokenize <|-- LetterTokenizer

Class LowerCaseTokenizer {
      # TCHAR normalize()      
}

LetterTokenizer <|-- LowerCaseTokenizer

Class WhitespaceTokenizer {
      # bool isTokenChar()
}

CharTokenize <|-- WhitespaceTokenizer

Class KeywordTokenizer {
      - bool done
      - int bufferSize
      + Token* next()
}

Tokenizer <|-- KeywordTokenizer

Class StandardTokenizer {
      + Token* next()
}

Tokenizer <|- StandardTokenizer

@enduml
